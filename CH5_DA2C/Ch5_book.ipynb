{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 5 - Actor-Critic Models\n",
    "### Deep Reinforcement Learning in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "12\n",
      "[array([ 0,  1,  4,  9, 16, 25, 36, 49]), array([ 64,  81, 100, 121, 144, 169, 196, 225]), array([256, 289, 324, 361, 400, 441, 484, 529]), array([576, 625, 676, 729, 784, 841, 900, 961]), array([1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521]), array([1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209]), array([2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025]), array([3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969])]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "def square(x): #A\n",
    "    return np.square(x)\n",
    "x = np.arange(64) #B\n",
    "print(x)\n",
    "print(mp.cpu_count())\n",
    "pool = mp.Pool(8) #C\n",
    "squared = pool.map(square, [x[8*i:8*i+8] for i in range(8)])\n",
    "print(squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In process 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In process 1\n",
      "In process 2\n",
      "In process 3\n",
      "In process 4\n",
      "In process 5\n",
      "In process 6\n",
      "In process 7\n",
      "[array([ 0,  1,  4,  9, 16, 25, 36, 49]), array([ 64,  81, 100, 121, 144, 169, 196, 225]), array([256, 289, 324, 361, 400, 441, 484, 529]), array([576, 625, 676, 729, 784, 841, 900, 961]), array([1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521]), array([1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209]), array([2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025]), array([3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969])]\n"
     ]
    }
   ],
   "source": [
    "def square(i, x, queue):\n",
    "    print(\"In process {}\".format(i,))\n",
    "    queue.put(np.square(x))\n",
    "processes = [] #A\n",
    "queue = mp.Queue() #B\n",
    "x = np.arange(64) #C\n",
    "for i in range(8): #D\n",
    "    start_index = 8*i\n",
    "    proc = mp.Process(target=square,args=(i,x[start_index:start_index+8], queue)) \n",
    "    proc.start()\n",
    "    processes.append(proc)\n",
    "    \n",
    "for proc in processes: #E\n",
    "    proc.join()\n",
    "    \n",
    "for proc in processes: #F\n",
    "    proc.terminate()\n",
    "results = []\n",
    "while not queue.empty(): #G\n",
    "    results.append(queue.get())\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import gym\n",
    "import torch.multiprocessing as mp #A\n",
    "\n",
    "class ActorCritic(nn.Module): #B\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.l1 = nn.Linear(4,25)\n",
    "        self.l2 = nn.Linear(25,50)\n",
    "        self.actor_lin1 = nn.Linear(50,2)\n",
    "        self.l3 = nn.Linear(50,25)\n",
    "        self.critic_lin1 = nn.Linear(25,1)\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x,dim=0)\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = F.relu(self.l2(y))\n",
    "        actor = F.log_softmax(self.actor_lin1(y),dim=0) #C\n",
    "        c = F.relu(self.l3(y.detach()))\n",
    "        critic = torch.tanh(self.critic_lin1(c)) #D\n",
    "        return actor, critic #E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(t, worker_model, counter, params):\n",
    "    worker_env = gym.make(\"CartPole-v1\")\n",
    "    worker_env.reset()\n",
    "    worker_opt = optim.Adam(lr=1e-4,params=worker_model.parameters()) #A\n",
    "    worker_opt.zero_grad()\n",
    "    for i in range(params['epochs']):\n",
    "        if( (i+1) % 100 == 0):\n",
    "           print(\"worker :\",t,\"=> ⌈\",\"epoch\",i+1,\":\",len(rewards),\"⌋\")\n",
    "        worker_opt.zero_grad()\n",
    "        values, logprobs, rewards = run_episode(worker_env,worker_model) #B \n",
    "        actor_loss,critic_loss,eplen = update_params(worker_opt,values,logprobs,rewards) #C\n",
    "        counter.value = counter.value + 1 #D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(worker_env, worker_model):\n",
    "    state = torch.from_numpy(worker_env.env.state).float() #A\n",
    "    values, logprobs, rewards = [],[],[] #B\n",
    "    done = False\n",
    "    j=0\n",
    "    while (done == False): #C\n",
    "        j+=1\n",
    "        policy, value = worker_model(state) #D\n",
    "        values.append(value)\n",
    "        logits = policy.view(-1)\n",
    "        action_dist = torch.distributions.Categorical(logits=logits)\n",
    "        action = action_dist.sample() #E\n",
    "        logprob_ = policy.view(-1)[action]\n",
    "        logprobs.append(logprob_)\n",
    "        state_, _, done, _, info = worker_env.step(action.detach().numpy())\n",
    "        state = torch.from_numpy(state_).float()\n",
    "        if done: #F\n",
    "            reward = -10\n",
    "            worker_env.reset()\n",
    "        else:\n",
    "            reward = 1.0\n",
    "        rewards.append(reward)\n",
    "    return values, logprobs, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(worker_opt,values,logprobs,rewards,clc=0.1,gamma=0.95):\n",
    "        rewards = torch.Tensor(rewards).flip(dims=(0,)).view(-1) #A\n",
    "        logprobs = torch.stack(logprobs).flip(dims=(0,)).view(-1)\n",
    "        values = torch.stack(values).flip(dims=(0,)).view(-1)\n",
    "        Returns = []\n",
    "        ret_ = torch.Tensor([0])\n",
    "        for r in range(rewards.shape[0]): #B\n",
    "            ret_ = rewards[r] + gamma * ret_\n",
    "            Returns.append(ret_)\n",
    "        Returns = torch.stack(Returns).view(-1)\n",
    "        Returns = F.normalize(Returns,dim=0)\n",
    "        actor_loss = -1*logprobs * (Returns - values.detach()) #C\n",
    "        critic_loss = torch.pow(values - Returns,2) #D\n",
    "        loss = actor_loss.sum() + clc*critic_loss.sum() #E\n",
    "        loss.backward()\n",
    "        worker_opt.step()\n",
    "        return actor_loss, critic_loss, len(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/home/oraika0/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker : 0 => ⌈ epoch 100 : 77 ⌋\n",
      "worker : 11 => ⌈ epoch 100 : 106 ⌋worker :\n",
      " 10 => ⌈ epoch 100 : 79 ⌋\n",
      "worker : 6 => ⌈ epoch 100 : 186 ⌋\n",
      "worker : 3 => ⌈ epoch 100 : 95 ⌋\n",
      "worker :worker : 2  7 => ⌈ => ⌈epoch  100 :epoch  100134  ⌋\n",
      ": 60 ⌋\n",
      "worker : 4 => ⌈ epoch 100 : 70 ⌋\n",
      "worker : 9 => ⌈ epoch 100 : 198 ⌋\n",
      "worker : 1 => ⌈ epoch 100 : 196 ⌋\n",
      "worker : 5 => ⌈ epoch 100 : 247 ⌋\n",
      "worker : 8 => ⌈ epoch 100 : 214 ⌋\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     processes\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m processes: \u001b[38;5;66;03m#F\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m processes: \u001b[38;5;66;03m#G\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     p\u001b[38;5;241m.\u001b[39mterminate()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker : 0 => ⌈ epoch 200 : 455 ⌋\n",
      "worker : 10 => ⌈ epoch 200 : 443 ⌋\n",
      "worker : 9 => ⌈ epoch 200 : 278 ⌋\n",
      "worker : 7 => ⌈ epoch 200 : 277 ⌋\n",
      "worker : 3 => ⌈ epoch 200 : 340 ⌋\n",
      "worker : 4 => ⌈ epoch 200 : 377 ⌋\n",
      "worker : 6 => ⌈ epoch 200 : 202 ⌋\n",
      "worker : 2 => ⌈ epoch 200 : 388 ⌋\n",
      "worker : 11 => ⌈ epoch 200 : 710 ⌋\n",
      "worker : 1 => ⌈ epoch 200 : 167 ⌋\n",
      "worker : 5 => ⌈ epoch 200 : 435 ⌋\n",
      "worker : 8 => ⌈ epoch 200 : 356 ⌋\n",
      "worker : 0 => ⌈ epoch 300 : 258 ⌋\n",
      "worker : 7 => ⌈ epoch 300 : 379 ⌋\n",
      "worker : 3 => ⌈ epoch 300 : 238 ⌋\n",
      "worker : 4 => ⌈ epoch 300 : 265 ⌋\n",
      "worker : 1 => ⌈ epoch 300 : 264 ⌋\n",
      "worker : 9 => ⌈ epoch 300 : 428 ⌋\n",
      "worker : 10 => ⌈ epoch 300 : 394 ⌋\n",
      "worker : 6 => ⌈ epoch 300 : 163 ⌋\n",
      "worker : 2 => ⌈ epoch 300 : 204 ⌋\n",
      "worker : 11 => ⌈ epoch 300 : 168 ⌋\n",
      "worker : 5 => ⌈ epoch 300 : 159 ⌋\n",
      "worker : 8 => ⌈ epoch 300 : 218 ⌋\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "MasterNode = ActorCritic() #A\n",
    "MasterNode.share_memory() #B\n",
    "processes = [] #C\n",
    "params = {\n",
    "    'epochs':1000,\n",
    "    'n_workers':12,\n",
    "}\n",
    "counter = mp.Value('i',0) #D\n",
    "for i in range(params['n_workers']):\n",
    "    p = mp.Process(target=worker, args=(i,MasterNode,counter,params)) #E\n",
    "    p.start() \n",
    "    processes.append(p)\n",
    "for p in processes: #F\n",
    "    p.join()\n",
    "for p in processes: #G\n",
    "    p.terminate()\n",
    "\n",
    "print(counter.value,processes[1].exitcode) #H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/don/git/DeepReinforcementLearningInAction/venv/lib/python3.10/site-packages/gym/envs/classic_control/cartpole.py:211: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost\n",
      "Lost\n",
      "Lost\n",
      "Lost\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env.reset()\n",
    "\n",
    "for i in range(100):\n",
    "    state_ = np.array(env.env.state)\n",
    "    state = torch.from_numpy(state_).float()\n",
    "    logits,value = MasterNode(state)\n",
    "    action_dist = torch.distributions.Categorical(logits=logits)\n",
    "    action = action_dist.sample()\n",
    "    state2, reward, done, info, _ = env.step(action.detach().numpy())\n",
    "    if done:\n",
    "        print(\"Lost\")\n",
    "        env.reset()\n",
    "    state_ = np.array(env.env.state)\n",
    "    state = torch.from_numpy(state_).float()\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(worker_env, worker_model, N_steps=10):\n",
    "    raw_state = np.array(worker_env.env.state)\n",
    "    state = torch.from_numpy(raw_state).float()\n",
    "    values, logprobs, rewards = [],[],[]\n",
    "    done = False\n",
    "    j=0\n",
    "    G=torch.Tensor([0]) #A\n",
    "    while (j < N_steps and done == False): #B\n",
    "        j+=1\n",
    "        policy, value = worker_model(state)\n",
    "        values.append(value)\n",
    "        logits = policy.view(-1)\n",
    "        action_dist = torch.distributions.Categorical(logits=logits)\n",
    "        action = action_dist.sample()\n",
    "        logprob_ = policy.view(-1)[action]\n",
    "        logprobs.append(logprob_)\n",
    "        state_, _, done, info = worker_env.step(action.detach().numpy())\n",
    "        state = torch.from_numpy(state_).float()\n",
    "        if done:\n",
    "            reward = -10\n",
    "            worker_env.reset()\n",
    "        else: #C\n",
    "            reward = 1.0\n",
    "            G = value.detach()\n",
    "        rewards.append(reward)\n",
    "    return values, logprobs, rewards, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No bootstrapping\n",
      "0.010000000000000009 1.99\n",
      "With bootstrapping\n",
      "0.9901 2.9701\n"
     ]
    }
   ],
   "source": [
    "#Simulated rewards for 3 steps\n",
    "r1 = [1,1,-1]\n",
    "r2 = [1,1,1]\n",
    "R1,R2 = 0.0,0.0\n",
    "#No bootstrapping\n",
    "for i in range(len(r1)-1,0,-1): \n",
    "    R1 = r1[i] + 0.99*R1\n",
    "for i in range(len(r2)-1,0,-1):\n",
    "    R2 = r2[i] + 0.99*R2\n",
    "print(\"No bootstrapping\")\n",
    "print(R1,R2)\n",
    "#With bootstrapping\n",
    "R1,R2 = 1.0,1.0\n",
    "for i in range(len(r1)-1,0,-1):\n",
    "    R1 = r1[i] + 0.99*R1\n",
    "for i in range(len(r2)-1,0,-1):\n",
    "    R2 = r2[i] + 0.99*R2\n",
    "print(\"With bootstrapping\")\n",
    "print(R1,R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
